{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from model import VGG,CNN\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from util import get_file_list,data_split,imgDataset\n",
    "\n",
    "num_epoch = 500\n",
    "batch_size=64\n",
    "embedding_size=4096\n",
    "epoch_num=100\n",
    "step_per_epoch=1500\n",
    "save_model_epoch=30\n",
    "valid_ratio=0.01\n",
    "\n",
    "learning_rate={\n",
    "    0:  0.01,\n",
    "    40:0.001,\n",
    "    70:0.0001,\n",
    "}\n",
    "\n",
    "result_path='./result'\n",
    "\n",
    "\n",
    "vgg_face_2_training_face='data/vggface2_train_face_notmask/'\n",
    "dirs=sorted(os.listdir(vgg_face_2_training_face))\n",
    "n_classes=len(dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isdir(result_path):\n",
    "    os.mkdir(result_path)\n",
    "    \n",
    "record_path=os.path.join(result_path,'record.csv')\n",
    "record_fp=open(record_path,'w')\n",
    "record_fp.write('epoch,train_loss,train_acc,valid_loss,valid_acc\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list,label_list=get_file_list(vgg_face_2_training_face)\n",
    "train_x,train_y,valid_x,valid_y=data_split(image_list,label_list,valid_ratio=valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_2_train=imgDataset(file_list=train_x,label_list=train_y,transform=train_transform,image_size=(224,224))\n",
    "train_dataloader = DataLoader(vgg_face_2_train, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "\n",
    "vgg_face_2_valid=imgDataset(file_list=valid_x,label_list=valid_y,transform=train_transform,image_size=(224,224))\n",
    "valid_dataloader = DataLoader(vgg_face_2_valid, batch_size=batch_size*2, shuffle=True,num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(backbone_out_dim=embedding_size,out_dim=n_classes).cuda()\n",
    "loss = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate[0],momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_loss=100000000000000000000\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "\n",
    "    model.train() \n",
    "    train_loader_iter=iter(train_dataloader)\n",
    "\n",
    "    pbar=tqdm(range(step_per_epoch))\n",
    "    for _ in pbar:\n",
    "        try:\n",
    "            batch=next(train_loader_iter)\n",
    "        except StopIteration:\n",
    "            train_loader_iter=iter(train_dataloader)\n",
    "            batch=next(train_loader_iter)\n",
    "        batch_X,batch_y=batch\n",
    "        batch_X=batch_X.cuda()\n",
    "        batch_y=batch_y.cuda()\n",
    "        optimizer.zero_grad() \n",
    "        train_pred = model(batch_X.cuda()) \n",
    "        batch_loss = loss(train_pred, batch_y.cuda()) \n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        batch_acc=np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == batch_y.cpu().numpy())/batch_size\n",
    "        train_acc += batch_acc\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        pbar.set_description(\"Epoch {} training:\".format(epoch))\n",
    "        pbar.set_postfix(loss=batch_loss.item(),acc=batch_acc)\n",
    "        pbar.update()\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar=tqdm(valid_dataloader)\n",
    "        for batch in pbar:\n",
    "            batch_X,batch_y=batch\n",
    "            batch_X=batch_X.cuda()\n",
    "            batch_y=batch_y.cuda()\n",
    "            val_pred = model(batch_X.cuda())\n",
    "            batch_loss = loss(val_pred, batch_y.cuda())\n",
    "            \n",
    "            batch_acc=np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == batch_y.cpu().numpy())/(batch_size*2)\n",
    "            val_acc += batch_acc\n",
    "            val_loss += batch_loss.item()\n",
    "            \n",
    "            pbar.set_description(\"Epoch {} valid:\".format(epoch))\n",
    "            pbar.set_postfix(loss=batch_loss.item(),acc=batch_acc)\n",
    "            pbar.update()\n",
    "    \n",
    "    train_loss=train_loss/step_per_epoch\n",
    "    train_acc=train_acc/step_per_epoch\n",
    "    val_loss=val_loss/len(valid_dataloader)\n",
    "    val_acc=val_acc/len(valid_dataloader)\n",
    "    print('Epoch {}|train_loss:{}|train_acc:{}|valid_loss:{}|valid_acc:{}'.format(epoch,train_loss,train_acc,val_loss,val_acc))\n",
    "    record_fp.write('{},{},{},{},{}\\n'.format(epoch,train_loss,train_acc,val_loss,val_acc))\n",
    "    record_fp.flush()\n",
    "    if epoch+1 in learning_rate:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate[epoch+1]\n",
    "    if val_loss <min_val_loss:\n",
    "        torch.save(model.state_dict(),os.path.join(result_path,'best_model.pth'))\n",
    "    if (epoch+1) % save_model_epoch==0:\n",
    "        torch.save(model.state_dict(),os.path.join(result_path,'model_{}.pth'.format(epoch)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
